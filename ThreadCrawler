package crawler;

import dao.Project;
import dao.ProjectDao;

import java.io.IOException;
import java.security.KeyManagementException;
import java.security.NoSuchAlgorithmException;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.*;

public class ThreadCrawler extends Crawler {
    public ThreadCrawler() throws KeyManagementException, NoSuchAlgorithmException {
    }
    public static void main(String[] args) throws NoSuchAlgorithmException, KeyManagementException, IOException {
        long startTime = System.currentTimeMillis();

        // 使用多线程的方式重新组织核心逻辑，访问 GitHub API 变成并行式
        ThreadCrawler threadCrawler = new ThreadCrawler();
        // 1. 获取首页内容
        String html = threadCrawler.getPage("https://github.com/akullpp/awesome-java/blob/master/README.md");
        // 2. 分析项目列表
        List<Project> projects = threadCrawler.parseProjectList(html);

        long startCallAPI = System.currentTimeMillis();
        // 3. 遍历项目列表，就要使用多线程的方式，用到线程池
        // 创建固定大小的线程池
        // ExecutorService 有两种提交任务的操作
        // a) execute: 不关注任务的结果
        // b) submit: 关注任务的结果
        // 此处使用 submit 最主要的目的是能够知道当前线程池中所有任务什么时候能够完成
        // 等到所有任务结束之后再保存数据
        List<Future<?>> taskResults = new ArrayList<>();
        ExecutorService executorService = Executors.newFixedThreadPool(30);
        for (Project project : projects) {
            // 例子：领导记录小本本来知道员工的任务进度
            Future<?> taskResult = executorService.submit(new CrawlerTask(project, threadCrawler));
            taskResults.add(taskResult);
        }
        // 等待所有线程池中的任务执行结束，再进行下一步操作
        for (Future<?> taskResult : taskResults) {
            // 调用 get 方法就会阻塞，阻塞到该任务执行完毕，get 才会返回
            try {
                taskResult.get();
            } catch (InterruptedException | ExecutionException e) {
                e.printStackTrace();
            }
        }
        // 代码执行到这一步，说明所有任务都执行结束，结束线程池
        executorService.shutdown(); // 卸磨杀驴

        long finishCallAPI = System.currentTimeMillis();
        System.out.println("调用 API 时间" + (finishCallAPI - startCallAPI));
        // 原始结果：34秒

        // 4. 保存到数据库
        ProjectDao projectDao = new ProjectDao();
        for (Project project : projects) {
            projectDao.save(project);
        }

        System.out.println("整体程序执行时间：" + (System.currentTimeMillis() - startTime));
        // 原始结果：64秒
    }
    static class CrawlerTask implements Runnable {
        private Project project;
        private ThreadCrawler threadCrawler;

        public CrawlerTask(Project project, ThreadCrawler threadCrawler) {
            this.project = project;
            this.threadCrawler = threadCrawler;
        }

        @Override
        public void run() {
            // 依赖两种对象：
            // project 对象，crawler 对象（调用对应的方法完成抓取）

            // 基本步骤
            try {
                // 1. 调用 API 获取项目数据
                System.out.println("crawling " + project.getName() + "....");
                String repoName = threadCrawler.getRepoName(project.getUrl());
                String jsonString = threadCrawler.getRepoInfo(repoName);
                // 2. 解析项目数据
                threadCrawler.parseRepoInfo(jsonString, project);
                System.out.println("crawling " + project.getName() + "done!");
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}
